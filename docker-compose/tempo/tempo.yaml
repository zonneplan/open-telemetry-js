server:
  http_listen_port: 3200
query_frontend:
  search:
    duration_slo: 5s
    throughput_bytes_slo: 1.073741824e+09
  trace_by_id:
    duration_slo: 5s
distributor:
  receivers:
    otlp:
      protocols:
        http:
          endpoint: "0.0.0.0:4318"
        grpc:
          endpoint: "0.0.0.0:4317"
ingester:
  max_block_duration: 5m
compactor:
  compaction:
    block_retention: 240h

storage:
  trace:
    backend: local
    local:
      path: /tmp/tempo/traces
    pool:
      max_workers: 100
      queue_depth: 10000

metrics_generator:
  metrics_ingestion_time_range_slack: 30s
  registry:
    external_labels:
      source: tempo
      cluster: docker-compose
  storage:
    path: /tmp/tempo_metrics
    remote_write:
      - url: http://prometheus:9090/api/v1/write
        send_exemplars: true
  processor:
    service_graphs:
      max_items: 100000
      dimensions:
        - "deployment.environment"
        - "service.namespace"
    span_metrics:
      dimensions:
        - "deployment.environment"
        - "service.namespace"
overrides:
  defaults:
    global:
      max_bytes_per_trace: 50000000
    metrics_generator:
      processors: [ service-graphs, span-metrics ]
    ingestion:
      burst_size_bytes: 40000000
      rate_limit_bytes: 30000000
      max_traces_per_user: 1000000
